{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Prepare the notebook. Run this cell first.'''\n",
    "import os, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Set parameters.  Run this cell before all others.'''\n",
    "study_name = '' #Change this to match your PLINK binary filestem (*.bed, *.bim, *.bam).\n",
    "thousand_genomes_filestem = '~/data/1kGP/1kGP_no_ATCG_LD_pruned' #This dataset contains 36.5M LD-pruned 1kGP variants.\n",
    "min_maf = 0.01 #Remove variants below this frequency. Set to 0 to keep all variants.\n",
    "max_missing_sample_callrate = 0.03 #Remove samples that have greater than this percent of missing genotypes (\"sample callrate\").\n",
    "max_missing_marker_callrate = 0.03 #Remove SNPs that have greater than this percent of missing calls (\"marker callrate\").\n",
    "max_IBD = 0.125 #Remove samples that have identity by state greater than this coefficient of relationship (first cousins).\n",
    "min_HWE_p = 0.00001 #Remove SNPs with HWE exact test p-values lower than this.\n",
    "min_diffmiss_p = 0.00001 #Remove SNPs with differential missingness test p-values lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get the current instance's number of CPU cores and RAM.'''\n",
    "ncpu_string = !nproc #Linux command to return the number of CPUs.\n",
    "ncpu = int(ncpu_string[0]) #Convert to Python integer.\n",
    "ram_string = !cat /proc/meminfo | fgrep MemTotal | perl -lane 'use POSIX; print floor($F[1] / 1024) #Convert from kB to MB'\n",
    "ram = int(ram_string[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Make analysis directory and upload your data'''\n",
    "\n",
    "import os\n",
    "study_dir = '/clink/' + study_name #Can change this variable to suit your study. \n",
    "#The base directory, /clink/, is the mountpoint for the encrypted EBS device.\n",
    "if not os.path.isdir(study_dir): os.mkdir(study_dir)\n",
    "%cd {study_dir}\n",
    "\n",
    "#You can either upload data to the EC2 instance using the key pair you specified at instance launch,\n",
    "#  for instance using scp from a system that has your data,\n",
    "#  or you can fetch the data from this instance using SFTP/rsync/curl/wget/s3\n",
    "\n",
    "#Remember that if you want to pull data from a private S3 bucket, the EC2 instance needs to assume an IAM role,\n",
    "#  and that bucket must be configured for the EC2 instance's IAM role.\n",
    "\n",
    "#In this example, I used scp from a firewalled and secured workstation to securely upload a Plink study to the EC2 instance.\n",
    "#I used a command like this from my workstation:\n",
    "#scp -i my_key_pair.pem my_study.* ec2-user@<IPv4_public_IP>:/gwas/my_study/\n",
    "#  ..where <IPv4_public_IP> is the public IPv4 address of the EC2 instance running this notebook.\n",
    "\n",
    "input_filestem  = study_name #This variable will be used throughout QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Instantiate results object to hold QC results at each step.'''\n",
    "class Results():\n",
    "    '''Class to hold results of each QC step.'''\n",
    "    def __init__(self):\n",
    "        self.results = pd.DataFrame(columns=['step_number', 'step_name', 'n_snps', 'n_samples']) #Declare empty DataFrame to update.\n",
    "    def add_result(self, result):\n",
    "        self.results = self.results.append(result, ignore_index=True)\n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "    \n",
    "class Result():\n",
    "    '''Class to hold results of a single QC step.'''\n",
    "    def __init__(self, step_number, step_name, n_snps_and_samples):\n",
    "        self.result = pd.Series({'step_number': step_number,\n",
    "                                 'step_name': step_name,\n",
    "                                 'n_snps': n_snps_and_samples[0],\n",
    "                                 'n_samples': n_snps_and_samples[1]})\n",
    "        self.result.reindex(index=['step_number', 'step_name', 'n_snps', 'n_samples'])\n",
    "    def get_result(self):\n",
    "        return self.result #Simple accessor.\n",
    "    \n",
    "def count_snps_and_samples(filestem):\n",
    "    '''Given a string representing a binary Plink filestem, count the samples and SNPs.'''\n",
    "    snp_count, sample_count = 0, 0\n",
    "    bim_file_name, fam_file_name = filestem + '.bim', filestem + '.fam'\n",
    "    with open(bim_file_name) as bim, open(fam_file_name) as fam:\n",
    "        for line in bim: snp_count += 1\n",
    "        for line in fam: sample_count += 1\n",
    "    return snp_count, sample_count #Tuple.\n",
    "    \n",
    "results = Results() #Instantiate results object to keep track of QC results at each step.\n",
    "results.add_result(Result(0, 'Initial dataset', count_snps_and_samples(input_filestem)).get_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''1) Run sex check using plink.'''\n",
    "\n",
    "#This should generate a *.sexcheck file for the study:\n",
    "!plink --bfile $input_filestem --check-sex --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sexcheck_file = input_filestem + '.sexcheck'\n",
    "sexprobs_file = input_filestem + '.sexprobs'\n",
    "\n",
    "!fgrep PROBLEM $sexcheck_file > $sexprobs_file\n",
    "sexproblems = !cat $sexprobs_file | wc -l\n",
    "print(\"Number of gender discordances detected: \" + str(sexproblems))\n",
    "\n",
    "#Save the FID and IID of the individuals that failed qc, if any.\n",
    "#It's okay to generate an empty file here - we'll count the lines of each fail-* file later for a sumamry.\n",
    "!perl -lne 's/^\\s+//; @f = split; print join \"\\t\", (@f[0..1])' $sexprobs_file >fail-sexcheck-qc.txt\n",
    "\n",
    "#At this point, inspect the reasons for any gender discordances.  In this case, some genders are missing in the ped file:\n",
    "!head -1 $sexcheck_file #For the header.\n",
    "!head -5 $sexprobs_file #Check out the first 5 discordances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Exclude samples that failed sexcheck QC.'''\n",
    "!plink --bfile $input_filestem --remove fail-sexcheck-qc.txt --make-bed --out $input_filestem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(1, 'Sexcheck', count_snps_and_samples(input_filestem)).get_result())\n",
    "results.get_results() #See the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''2) Marker callrate.'''\n",
    "!plink --bfile $input_filestem --geno $max_missing_marker_callrate --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(2, 'Marker callrate', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''3) Sample callrate.'''\n",
    "!plink --bfile $input_filestem --mind $max_missing_sample_callrate --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(3, 'Sample callrate', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''4) MAF'''\n",
    "!plink --bfile $input_filestem --maf $min_maf --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(4, 'MAF', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''5) IBD'''\n",
    "'''Generate a missingness report and LD-pruned variants first.'''\n",
    "!plink --bfile $input_filestem --missing --out $input_filestem\n",
    "!plink --bfile $input_filestem --indep-pairwise 50 5 0.2 --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''If the above output pruned too few or too many SNPs, adjust the linkage R^2 value \n",
    "Increase R^2 to retain more SNPs, decrease to prune more.\n",
    "The goal is to end up with about 100k SNPs for a GWAS study (>= 500k SNPs genome-wide).\n",
    "Then proceed with identification of related samples.'''\n",
    "prune_in_file = input_filestem + '.prune.in'\n",
    "unlinked_variant_count = !cat $prune_in_file | wc -l\n",
    "print \"Unlinked (LD-pruned) genetic variant count: \" + str(unlinked_variant_count)\n",
    "!plink --bfile $input_filestem --extract $prune_in_file --genome --out $input_filestem\n",
    "#That command should generate a *.genome file.  This might be the most computationally heavy cell in the notebook.\n",
    "#IBD calculation \"used to take weeks\" according to a collaborator.  Plink's IBD computation is now fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genome_file = input_filestem + '.genome'\n",
    "imiss_file = input_filestem + '.imiss'\n",
    "#Clean up the whitespace:\n",
    "!perl -i -lpe 's/^\\s+//; s/\\s+/\\t/g;' $genome_file $imiss_file\n",
    "\n",
    "#Now plot the relationships. This will take a while for a huge study!\n",
    "%Rpush genome_file\n",
    "%R genome <- read.table(genome_file, header=T)\n",
    "%R library(ggplot2)\n",
    "%R library(cowplot)\n",
    "%R ggplot(genome, aes(x=Z0, y=Z1, colour=RT)) + geom_point(alpha=0.3)\n",
    "%R ggsave('IBD_plot.pdf') #Save vectorized plot for presentation.\n",
    "%R ggsave('IBD_plot.png') #For notebook display.\n",
    "Image('IBD_plot.png')\n",
    "#Inspect this plot for regions of known relationship types.  For a GWAS of presumably unrelated individuals,\n",
    "#  most points should appear in the bottom right (Z0 near 1, Z1 near 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''These are the expected values for known types of relationships, to help you interpret this plot above:\n",
    "Z0    Z1    Z2    Kinship    Relationship\n",
    "0     0     1     1          Duplicated sample, monozygotic twin, or clone (future)\n",
    "0     1.0   0     0.5        Parent-offspring\n",
    "0.25  0.5   0.25  0.5        Full siblings\n",
    "0.5   0.5   0     0.25       Half siblings\n",
    "0.75  0.25  0     0.125      Cousins\n",
    "1.0   0     0     0          Unrelated\n",
    "'''\n",
    "#This image from the R Graphical Manual (http://www.imsbio.co.jp/RGM/R_rdfile?f=GWASTools/man/ibdPlot.Rd&d=R_BC)\n",
    "#  might also be helpful.\n",
    "Image('http://www.imsbio.co.jp/RGM-files/R_BC/result/GWASTools/ibdPlot.Rd_001_medium.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Generate a file containing FID:IID pairs of individuals to be excluded on the basis of relatedness.\n",
    "Exclude the individual with greater missingness from any pair of individuals that are related more than first cousins.'''\n",
    "\n",
    "imiss, removed = dict(), set()\n",
    "\n",
    "with open(imiss_file) as imiss_in, open(genome_file) as genome_in, open('fail-IBD-QC.txt', 'w') as fail_IBD_out:\n",
    "    #Read the missingness into a dictionary.\n",
    "    header = imiss_in.readline()\n",
    "    for line in imiss_in:\n",
    "        fid, iid, miss_pheno, n_miss, n_geno, f_miss = line.rstrip().split(\"\\t\") #File was already whitespace-cleaned.\n",
    "        imiss[(fid, iid)] = float(f_miss) #Key by FID:IID tuple, value by F_MISS (missing frequency).\n",
    "        \n",
    "    #Now exclude related samples. Drop whichever one has higher missingness.\n",
    "    header = genome_in.readline()\n",
    "    for line in genome_in:\n",
    "        fid1, iid1, fid2, iid2, rt, ez, z0, z1, z2, pi_hat, phe, dst, ppc, ratio = line.rstrip().split(\"\\t\")\n",
    "        if float(pi_hat) > 0.185:\n",
    "            if imiss[(fid1, iid1)] >= imiss[(fid2, iid2)]: #The first sample has higher missingness.\n",
    "                if (fid1, iid1) not in removed:\n",
    "                    fail_IBD_out.write(\"\\t\".join([fid1, iid1]) + \"\\n\")\n",
    "                    removed.add((fid1, iid1)) #Remember that we already excluded this FID:IID pair.\n",
    "            else: #The second sample has higher missingness.\n",
    "                if (fid2, iid2) not in removed:\n",
    "                    fail_IBD_out.write(\"\\t\".join([fid2, iid2]) + \"\\n\")\n",
    "                    removed.add((fid2, iid2))\n",
    "\n",
    "fail_IBD_count = !cat fail-IBD-QC.txt | wc -l\n",
    "print \"Number of samples that failed IBD QC: \" + str(fail_IBD_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Now exclude the related samples from the study.'''\n",
    "!plink --bfile $input_filestem --remove fail-IBD-QC.txt --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(5, 'IBD', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''6) Outlying heterozygosity.\n",
    "First, visualize missingness and heterozygosity from reports.'''\n",
    "\n",
    "!plink --bfile $input_filestem --missing --het --out $input_filestem\n",
    "imiss_file = input_filestem + '.imiss'\n",
    "het_file   = input_filestem + '.het'\n",
    "\n",
    "#!head {imiss_file} #See how Plink generates some extra whitespace...\n",
    "!perl -i -lpe 's/^\\s+//; s/\\s+/\\t/g;' {imiss_file} {het_file} \n",
    "#!head {imiss_file} #Uncomment to see how this Perl one-liner cleaned up these two files for easy reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Plot missingness versus heterozygosity. Use Rmagic.'''\n",
    "\n",
    "%Rpush imiss_file het_file\n",
    "%R imiss <- read.table(imiss_file, header=T)\n",
    "%R het   <- read.table(het_file,   header=T)\n",
    "%R library(ggplot2)\n",
    "%R library(cowplot)\n",
    "\n",
    "#Calculate the log10 of the F_MISS and the mean heterozygosity (among non-missing genotypes).\n",
    "%R imiss$logF_MISS <- log10(imiss$F_MISS)\n",
    "%R het$meanHet     <-  (het$N.NM. - het$O.HOM.)/het$N.NM.\n",
    "\n",
    "%R -o summary_logF_MISS summary_logF_MISS <- summary(imiss$logF_MISS)\n",
    "print(\"Summary of log10(missingness): \" + str(summary_logF_MISS))\n",
    "\n",
    "%R -o summary_meanHet summary_meanHet <- summary(het$meanHet)\n",
    "print(\"Summary of mean heterozygosity: \" + str(summary_meanHet))\n",
    "\n",
    "%R imiss_and_het <- merge(imiss, het, by='IID')\n",
    "\n",
    "\n",
    "%R imiss_vs_het_scatterplot <- ggplot(imiss_and_het, aes(x=logF_MISS, y=meanHet)) + geom_point(alpha=0.3, colour='steelblue') + xlab(\"Proportion of Missing Genotypes (log10)\") + ylab(\"Mean Autosomal Heterozygosity\")\n",
    "%R ggsave('imiss_vs_het.pdf') #Save publication-quality PDF.\n",
    "%R ggsave('imiss_vs_het.png') #Save PNG for display in the notebook.\n",
    "Image('imiss_vs_het.png')\n",
    "#Inspect this plot for the distribution of missingness (x-axis) versus mean heterozygosity (y-axis).\n",
    "#One can exclude samples with outlying heterozygosity, e.g. more than 3 standard deviations below the mean.\n",
    "\n",
    "#Here's something similar in pure R:\n",
    "#%R plot(imiss$logF_MISS, het$meanHet, pch=1, xlab=\"Proportion of missing genotypes\", ylab=\"Heterozygosity rate\",axes=F); axis(2,at=c(0,0.05,0.10,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5),tick=T); axis(1,at=c(-3,-2,-1,0),labels=c(0.001,0.01,0.1,1)); abline(h=mean(het$meanHet) - (2 * sd(het$meanHet)), col=\"RED\",  lty=2); abline(h=mean(het$meanHet) - (3 * sd(het$meanHet)), col=\"gray\", lty=2); abline(h=mean(het$meanHet) + (2 * sd(het$meanHet)), col=\"red\",  lty=2); abline(h=mean(het$meanHet) + (3 * sd(het$meanHet)), col=\"gray\",  lty=2); abline(v=-1.522879, col=\"red\", lty=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Write file containing FID:IID pairs for individuals with outlying heterozygosity'''\n",
    "%R het.filt <- het[which( het$meanHet > (mean(het$meanHet) + 3 * sd(het$meanHet)) | het$meanHet < (mean(het$meanHet) - 3 * sd(het$meanHet)) ),]\n",
    "%R write.table(het.filt[,c(1,2)], file=\"fail-het-qc.txt\", sep=\"\\t\", row.names=F, col.names=F, quote=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fail_het_qc_count = !cat fail-het-qc.txt | wc -l\n",
    "print(\"Number of individuals who failed heterozygosity QC:\" + str(fail_het_qc_count))\n",
    "!plink --bfile $input_filestem --remove fail-het-qc.txt --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(6, 'Outlying heterozygosity', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Now that we've excluded related samples and optionally samples with outlying autosomal heterozygosity,\n",
    "we repeat the marker callrate, sample callrate, and MAF steps before finally proceeding to HWE/diffmiss/PCA.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''7) Marker callrate.  This might not remove any SNPs, but it is important to retain guarantees about callrate.'''\n",
    "!plink --bfile $input_filestem --geno $max_missing_marker_callrate --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(7, 'Marker callrate', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''8) Sample callrate.'''\n",
    "!plink --bfile $input_filestem --mind $max_missing_sample_callrate --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(8, 'Sample callrate', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''9) MAF'''\n",
    "!plink --bfile $input_filestem --maf $min_maf --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(9, 'MAF', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''10) HWE. If you wish to base this test only on cases,\n",
    "which requires your PED file to have accurate case/control phenotype encodings,\n",
    "you can omit the --include-nonctrl option.\n",
    "The mid-p modifier is recommended by Plink.'''\n",
    "\n",
    "!plink --bfile $input_filestem --hwe $min_HWE_p midp include-nonctrl --make-bed --out $input_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(10, 'HWE', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''11) Differential missingness (differential sample callrate).\n",
    "This step relies on accurate case/control phenotype encodings in the FAM file.'''\n",
    "!plink --bfile $input_filestem --test-missing --out $input_filestem\n",
    "diffmiss_file = input_filestem + '.missing'\n",
    "!perl -i -lpe 's/^\\s+//; s/\\s+/\\t/g;' {diffmiss_file} #Clean up whitespace.\n",
    "diffmiss_snp_count = 0\n",
    "with open('fail-diffmis-qc.txt', 'w') as fail_diffmiss, open(diffmiss_file) as diffmiss:\n",
    "    header = diffmiss.readline() #Skip header line.\n",
    "    for line in diffmiss:\n",
    "        CHROM, SNP, F_MISS_A, F_MISS_U, P = line.rstrip().split(\"\\t\")\n",
    "        if P < min_diffmiss_p:\n",
    "            diffmiss_snp_count += 1\n",
    "            fail_difmiss.write(SNP + \"\\n\")\n",
    "\n",
    "print \"SNPs that failed differential missingness:\", diffmiss_snp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Exclude variants that failed differential missingness (if any).'''\n",
    "if diffmiss_snp_count > 0:\n",
    "    !plink --bfile $input_filestem --exclude diffmiss_file --make-bed --out $input_filestem\n",
    "else:\n",
    "    print \"No SNPs show differential missingness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(11, 'Differential missingness', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''12) PCA'''\n",
    "#First, try to merge the study's genotypes with the 1000 Genomes Project, phase 3, version 5a.\n",
    "#We'll try a 5 step approach: merge, flip, merge, exclude, merge.\n",
    "merged_filestem = 'merged' #We can do this in 5 steps with 3 filestems.  This is the output filestem.\n",
    "flipped_filestem = 'flipped' #This filestem holds flipped 1kGP variants that failed the first merge.\n",
    "flipmerged_filestem = 'flipmerged' #This filestem holds the results of the merge with the flipped 1kGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''First, we'll intersect the rsIDs between the two datasets to thin down the size of the merged dataset.\n",
    "Plink's --bmerge currently generates the union, which in this case will result in at least the 36.5M variants\n",
    "from the 1000 Genomes Project.  Intersecting by ID might miss some rsID changes with identical chrom-pos-ref-alt.'''\n",
    "snps_in_study, snps_in_1kGP = set(), set() #Populate these with IDs, then intersect them.\n",
    "with open(input_filestem + '.bim') as study_bim, open(thousand_genomes_filestem + '.bim') as thousand_genomes_bim:\n",
    "    for line in study_bim:\n",
    "        fields = line.rstrip().split(\"\\t\")\n",
    "        snps_in_study.add(fields[1]) #The second column of the BIM file holds the rsID.\n",
    "    for line in thousand_genomes_bim:\n",
    "        fields = line.rstrip().split(\"\\t\")\n",
    "        snps_in_1kGP.add(fields[1])\n",
    "        \n",
    "print \"SNPs in study (post-QC):\", len(snps_in_study)\n",
    "print \"SNPs in 1000 Genomes Project:\", len(snps_in_1kGP)\n",
    "intersection_snps = snps_in_study.intersection(snps_in_1kGP) #Python set.\n",
    "print \"Intersection:\", len(intersection_snps)\n",
    "with open('intersection_snps.txt', 'w') as intersection_snps_file:\n",
    "    for snp in intersection_snps:\n",
    "        intersection_snps_file.write(snp + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Now generate a thinned down version of each study to merge, containing only intersecting SNPs.'''\n",
    "intersection_input_filestem = input_filestem + '_intersection'\n",
    "intersection_1kGP_filestem  = thousand_genomes_filestem + '_intersection'\n",
    "!plink --bfile $input_filestem --extract intersection_snps.txt --make-bed --out $intersection_input_filestem\n",
    "!plink --bfile $thousand_genomes_filestem --extract intersection_snps.txt --make-bed --out $intersection_1kGP_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1: Try an initial merge.\n",
    "!plink --bfile $intersection_input_filestem --bmerge $intersection_1kGP_filestem --make-bed --out $merged_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Now, try to flip the SNPs that failed to merge.'''\n",
    "missnp_file = merged_filestem + '-merge.missnp' #This holds the variants that failed to merge.\n",
    "missnp_count = !wc -l $missnp_file\n",
    "print \"SNPs that failed to merge:\", missnp_count\n",
    "print \"Flipping SNPs that failed to merge.\\n\"\n",
    "!plink --bfile $intersection_1kGP_filestem --flip $missnp_file --make-bed --out $flipped_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Now try to merge with the flipped SNPs.'''\n",
    "!plink --bfile $intersection_input_filestem --bmerge $flipped_filestem --make-bed --out $flipmerged_filestem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''If that above step didn't end in \"Error: XXX variants with 3+ alleles present\",\n",
    "then you have a successful merge and can skip the next step (exclusion of flipped SNPs that failed to merge).'''\n",
    "flipmerged_missnp_file = flipmerged_filestem + '-merge.missnp'\n",
    "if os.path.exists(flipmerged_missnp_file): #If this file exists, this final step needs to be carried out.\n",
    "    flipmerged_missnp_count = !wc -l flipmerged_missnps_file\n",
    "    print \"SNPs that failed to merge after flipping:\", flipmerged_missnp_count\n",
    "    print \"Excluding flipped SNPs that failed to merge.\\n\"\n",
    "    !plink --bfile $flipped_filestem --exclude $flipmerged_missnp_file --make-bed --out $flipped_filestem\n",
    "    !plink --bfile $input_filestem --bmerge $flipped_filestem --make-bed --out $flipmerged_filestem\n",
    "    #Make sure that step generated a successful merge.\n",
    "else:\n",
    "    print \"Merge was successful: no need to exclude variants.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Now that the study is successfully merged with 1kGP, call PC1-20 and make plots.'''\n",
    "!plink --bfile $flipmerged_filestem --pca header tabs var-wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Now add a column that contains the population label from the 1000 Genomes project.'''\n",
    "with open('plink.eigenvec') as eigenvec_in, open('/clink/1kGP/1kGP_populations.tsv') as populations_in, open('plink.eigenvec.labeled', 'w') as eigenvec_out:\n",
    "    eigenvec_header = eigenvec_in.readline().rstrip() + \"\\tPopulation\\tSuperpopulation\\n\" #Fix up header.\n",
    "    eigenvec_out.write(eigenvec_header)\n",
    "    populations = dict() #Key by sample ID (IID), value by population (26 different populations).\n",
    "    populations_header = populations_in.readline() #\"Sample Population\\n\"\n",
    "    for line in populations_in:\n",
    "        sample, population = line.rstrip().split(\"\\t\") #Tab delimited.\n",
    "        populations[sample] = population #One of 26 populations.\n",
    "    \n",
    "    superpopulations = {'CHB': 'EAS', 'JPT': 'EAS', 'CHS': 'EAS', 'CDX': 'EAS', 'KHV': 'EAS',\n",
    "                        'CEU': 'EUR', 'TSI': 'EUR', 'FIN': 'EUR', 'GBR': 'EUR', 'IBS': 'EUR',\n",
    "                        'YRI': 'AFR', 'LWK': 'AFR', 'GWD': 'AFR', 'MSL': 'AFR', 'ESN': 'AFR', 'ASW': 'AFR', 'ACB': 'AFR',\n",
    "                        'MXL': 'AMR', 'PUR': 'AMR', 'CLM': 'AMR', 'PEL': 'AMR',\n",
    "                        'GIH': 'SAS', 'PJL': 'SAS', 'BEB': 'SAS', 'STU': 'SAS', 'ITU': 'SAS'}\n",
    "    \n",
    "    for line in eigenvec_in:\n",
    "        fields = line.rstrip().split(\"\\t\") #FID, IID, PC1, PC2, ..., PC20\n",
    "        IID = fields[1]\n",
    "        if populations.has_key(fields[1]): #IID is in fields[1].\n",
    "            population = populations.get(IID, study_name) #Assume all non-1kGP samples are in the study.\n",
    "            superpopulation = superpopulations.get(population, \"NA\")\n",
    "        else:\n",
    "            population = study_name\n",
    "            superpopulation = study_name\n",
    "        eigenvec_out.write(\"\\t\".join(fields) + \"\\t\" + population + \"\\t\" + superpopulation + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Now plot PC1 against PC2.'''\n",
    "%R pca <- read.table(\"plink.eigenvec.labeled\", sep=\"\\t\", header=T)\n",
    "%R library(ggplot2)\n",
    "%R library(cowplot, quietly=T)\n",
    "%R pc1_vs_pc2_plot <- ggplot(pca, aes(x=PC1, y=PC2, colour=Superpopulation)) + geom_point(alpha=0.3)\n",
    "%R ggsave('pc1_vs_pc2_plot.pdf')\n",
    "%R ggsave('pc1_vs_pc2_plot.png') #For viewing in the notebook.\n",
    "Image(\"pc1_vs_pc2_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Update running Results() object.'''\n",
    "results.add_result(Result(12, 'PCA', count_snps_and_samples(input_filestem)).get_result())\n",
    "#results.get_results() #Feel free to uncomment this to see the running result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Final step: save results table.'''\n",
    "results.get_results().to_csv('GWAS_QC_results.csv', index=False)\n",
    "results.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''QC is now complete!  Download this notebook, the high-resolution graphics, and the final Plink filestem.\n",
    "You can download from the running instance using the following command. You just need to use the key-pair file\n",
    "for the EC2 instance (substitute its file name for my_key_pair.pem)'''\n",
    "!rm *~ #Clean up intermediate files.\n",
    "\n",
    "ip_str = !wget -qO- http://instance-data/latest/meta-data/public-ipv4 #EC2 URL for getting the public IPv4 address.\n",
    "ip_address = ip_str[0] #Convert to Python string.\n",
    "sftp_target = 'ec2-user@' + str(ip_address) + ':' #Base SFTP server endpoint.\n",
    "dataset_sftp_target = sftp_target + study_dir + '/' + input_filestem + '.*' #For the cleaned up Plink study.\n",
    "pdf_sftp_target = sftp_target + study_dir + '/' + '*.pdf' #For PDF grahics generated during GWAS QC.\n",
    "csv_sftp_target = sftp_target + study_dir + '/' + 'GWAS_QC_results.csv'\n",
    "pca_sftp_target = sftp_target + study_dir + '/' + 'plink.eigenvec' #Contains PC1-20, keyed by FID and IID.\n",
    "notebook_sftp_target = sftp_target + '/clink/CLINK/GWAS_QC.ipynb' #If you renamed the notebook,\n",
    "# change this to the new notebook name.\n",
    "\n",
    "print 'sftp -i my_key_pair.pem ' + dataset_sftp_target\n",
    "print 'sftp -i my_key_pair.pem ' + notebook_sftp_target\n",
    "print 'sftp -i my_key_pair.pem ' + pdf_sftp_target\n",
    "print 'sftp -i my_key_pair.pem ' + csv_sftp_target\n",
    "print 'sftp -i my_key_pair.pem ' + pca_sftp_target\n",
    "\n",
    "'''Advanced users may use git to clone the notebook and S3 to store the data.\n",
    "HOWEVER, note that including any credentials (e.g. git profile, AWS credentials)\n",
    "on an image of the EC2 instance is a SECURITY RISK!\n",
    "If you add any credentials to the EC2 instance, DO NOT TAKE AN AMI IMAGE\n",
    "OR AN EBS SNAPSHOT becuase the image will contain your credentials.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Now that you have downloaded the notebook, cleaned up dataset, PDF graphics, and CSV report of QC,\n",
    "you can go ahead and delete the CloudFormation stack from the AWS console.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
